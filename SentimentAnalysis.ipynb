{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b4ef4c-21cd-428c-9464-8db30b867d40",
   "metadata": {},
   "source": [
    "%%capture \n",
    "!pip install import-ipynb \n",
    "!pip install textblob \n",
    "!pip install spacy \n",
    "!pip install nltk \n",
    "!pip install -U sklearn \n",
    "!pip install googletrans==3.1.0a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ancient-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import unicodedata\n",
    "import glob\n",
    "\n",
    "from leia import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from googletrans import Translator\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526d2ef1-803c-4fcd-a7da-e6f1e82807fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pt-core-news-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.2.0/pt_core_news_sm-3.2.0-py3-none-any.whl (22.2 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pt-core-news-sm==3.2.0) (3.2.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (0.9.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (58.0.4)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.20.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.4.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.27.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.0.7)\n",
      "Requirement already satisfied: click<8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.0.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (21.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click<8.1.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.10)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "#Execute de line below to download de 'pt_core_news_sm'\n",
    "!python -m spacy download pt_core_news_sm\n",
    "\n",
    "translator = Translator(service_urls=['translate.googleapis.com'])\n",
    "#nltk.download('punkt')\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "#nltk.download('stopwords')\n",
    "sw = set(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c89906-5207-4624-ae5a-16be6ff5c691",
   "metadata": {},
   "source": [
    "## Prepeocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e63566-6b63-4776-920a-ab64869de470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tt_username(text):\n",
    "    text = str(text)\n",
    "    no_tt_username = re.sub(r'\\@\\S+', '', text)\n",
    "    return no_tt_username\n",
    "\n",
    "def identify_emoticons(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\:\\-?\\)+', ' cara feliz ', text)\n",
    "    text = re.sub(r'\\:\\-?[dDpP]+', ' cara feliz ', text)\n",
    "    text = re.sub(r'\\:\\-?\\'?\\(+', ' cara triste ', text)\n",
    "    text = re.sub(r'\\>\\:\\-?\\(+', ' cara brava ', text)\n",
    "    return text\n",
    "\n",
    "def remove_hashtags(text):\n",
    "    text = str(text)\n",
    "    no_hashtags = re.sub(r'\\#\\S+', '', text)\n",
    "    return no_hashtags\n",
    "\n",
    "def remove_phone(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'(\\(?(\\d{2,3})\\)?)?\\ ?\\d{4,5}\\-?\\ ?\\d{4}', ' ', text)\n",
    "    return text\n",
    "\n",
    "def remove_url(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'https?\\:\\/\\/\\S+', ' ', text)\n",
    "    text = re.sub(r'www\\.\\S+', '', text)\n",
    "    text = re.sub(r'[a-zA-Z|.]+\\.com(\\.br)?', ' link ', text)\n",
    "    return text\n",
    "\n",
    "def remove_date(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'((\\d{1,2}\\/)(\\d{1,2}\\/?)(\\d{2,4})?)', ' ', text)\n",
    "    text = re.sub(r'((\\d{1,2}\\-)(\\d{1,2}\\-?)(\\d{2,4})?)', ' ', text)\n",
    "    text = re.sub(r'((\\d+(\\s+[deDE]+\\s+)[aA-zZ|รง|ร]+((\\s+[deDE]+\\s+)\\d+)?))', ' ', text)\n",
    "    return text\n",
    "\n",
    "def remove_hour(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'(\\d+)\\:(\\d+)[hH]?(\\:\\d+)?[hH]?[rsRS]\\w?', ' ', text)\n",
    "    text = re.sub(r'(\\d+)[hH](\\d+)', ' < hora > ', text)\n",
    "    return text\n",
    "\n",
    "def remove_number(text): \n",
    "    text = str(text)\n",
    "    text = re.sub(r'[0-9]', '', text)\n",
    "    return text\n",
    "\n",
    "def lowercase(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def remove_oneword(text):\n",
    "    text = str(text)\n",
    "    if len(text.split()) > 1:        \n",
    "        return text\n",
    "    return\n",
    "\n",
    "def remove_stopword(text):\n",
    "    text = str(text) \n",
    "    text = [word for word in text.split() if word not in sw]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "def remove_accent(text):\n",
    "    text = str(text) \n",
    "    text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode(\"utf-8\")\n",
    "    return text\n",
    "\n",
    "def remove_emoji(text):\n",
    "    text = str(text)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U000E007F\"  \n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  \n",
    "                           u\"\\U0001F680-\\U0001F6FF\" \n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    return text\n",
    "\n",
    "def remove_punction(text): \n",
    "    text = str(text) \n",
    "    text = re.sub(r'[!\"#$%&\\'()*+,-.ยบ<>/:;=?@[/\\/\\]^_`{|}~]', ' ', text)\n",
    "    return text\n",
    "\n",
    "def preprocessing(data):\n",
    "    data = pd.Series(data)\n",
    "    data = data.apply(remove_tt_username)\n",
    "    data = data.apply(remove_hashtags)\n",
    "    data = data.apply(identify_emoticons)\n",
    "    data = data.apply(remove_url)\n",
    "    data = data.apply(remove_phone)\n",
    "    data = data.apply(remove_hour)\n",
    "    data = data.apply(remove_date)\n",
    "    data = data.apply(remove_number)\n",
    "    data = data.apply(remove_emoji)\n",
    "    data = data.apply(lowercase)\n",
    "    data = data.apply(remove_stopword)\n",
    "    data = data.apply(remove_accent)\n",
    "    data = data.apply(remove_punction)\n",
    "    data = data.apply(remove_oneword)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a939468c",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c723cf",
   "metadata": {},
   "source": [
    "### LeIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ed0f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def leia(text):\n",
    "    text = str(text)\n",
    "    result = analyzer.polarity_scores(text)\n",
    "    \n",
    "    #analisa a frase utilizando o compound\n",
    "    if result['compound'] >= 0.05:\n",
    "        return 'positivo'\n",
    "    elif result['compound'] <= -0.05:\n",
    "        return 'negativo'\n",
    "    else:\n",
    "        return 'neutro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14cc605a-93b8-45fa-8dba-c808f5045fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teste \"aspas\" teste\n"
     ]
    }
   ],
   "source": [
    "print('teste \"aspas\" teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd81173",
   "metadata": {},
   "source": [
    "### TextBlob + ReLi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9d2e29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textblob(sentence):\n",
    "    sentence = str(sentence)\n",
    "    blob = TextBlob(sentence)\n",
    "    result = 0\n",
    "    \n",
    "    #translate the text to english\n",
    "    try:\n",
    "        translation = translator.translate(sentence, src='pt', dest='en')\n",
    "        translation = translation.text\n",
    "        translation = TextBlob(translation)\n",
    "        result = translation.sentiment.polarity\n",
    "\n",
    "        if result > 0:\n",
    "            return 'positivo'\n",
    "        elif result < 0:\n",
    "            return 'negativo'\n",
    "        else:\n",
    "            return 'neutro'\n",
    "    except:\n",
    "        print('error to translate \"'+sentence+'\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47993bef",
   "metadata": {},
   "source": [
    "### OpLexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "558294b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lexico_v3.0.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "lines = [str(x.strip()) for x in lines]\n",
    "pol_dict = {}\n",
    "\n",
    "for line in lines:\n",
    "    word, _, pol, _ = line.split(',')\n",
    "    \n",
    "    if word not in pol_dict.keys():\n",
    "        pol_dict[word] = pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f3a6c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oplexion(text):\n",
    "    text = str(text)\n",
    "    doc = nlp(text)\n",
    "    pol = 0\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.text in pol_dict.keys():\n",
    "            if token.pos_ == 'VERB':\n",
    "                if token.lemma_ in pol_dict.keys():\n",
    "                    pol += int(pol_dict[str(token.lemma_)])\n",
    "                else:\n",
    "                    pol += int(pol_dict[str(token.text)])\n",
    "            else:\n",
    "                pol += int(pol_dict[str(token.text)])\n",
    "        else:\n",
    "            pol += 0\n",
    "        \n",
    "    if pol > 0:\n",
    "        return 'positivo'\n",
    "    elif pol < 0:\n",
    "        return 'negativo'\n",
    "    else:\n",
    "        return 'neutro'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a33f64b",
   "metadata": {},
   "source": [
    "### SentiLex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1124a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SentiLex-lem-PT01.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "lines = [str(x.strip()) for x in lines]\n",
    "pol_dict = {}\n",
    "\n",
    "for line in lines:\n",
    "    word, infos = line.split('.')\n",
    "    pol = infos.split(';')\n",
    "    pol = pol[3]\n",
    "    pol = pol[4:]\n",
    "    \n",
    "    if word not in pol_dict.keys():\n",
    "        pol_dict[word] = pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77400c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentilex(text):\n",
    "    text = str(text)\n",
    "    doc = nlp(text)\n",
    "    pol = 0\n",
    "    \n",
    "    for token in doc:\n",
    "        try:\n",
    "            if token.pos_ == 'VERB':\n",
    "                pol += int(pol_dict[str(token.lemma_)])\n",
    "            else:\n",
    "                pol += int(pol_dict[str(token.text)])\n",
    "        except KeyError:\n",
    "            pol += 0\n",
    "        \n",
    "    if pol > 0:\n",
    "        return 'positivo'\n",
    "    elif pol < 0:\n",
    "        return 'negativo'\n",
    "    else:\n",
    "        return 'neutro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "helpful-clerk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Date</th>\n",
       "      <th>Original_Tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Search</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bolsonaro</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ciro Gomes</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doria</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lula</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Tweet_Date  Original_Tweet\n",
       "Search                                \n",
       "Bolsonaro         1000            1000\n",
       "Ciro Gomes        1000            1000\n",
       "Doria             1000            1000\n",
       "Lula              1000            1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat(map(pd.read_csv, glob.glob('raw_data\\\\*2022-04-23*.csv')))[['Search', 'Tweet_Date', 'Original_Tweet']].reset_index(drop=True)\n",
    "data.groupby('Search').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "figured-murray",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "marine-brisbane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 217 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search</th>\n",
       "      <th>Tweet_Date</th>\n",
       "      <th>Original_Tweet</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>@ArthurWilliam_ @LulaOficial @ricardostuckert ...</td>\n",
       "      <td>antes  o ter sido presidente ter saqueado naca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>@CarlosBolsonaro @TerraBrasilnot Se ele trocas...</td>\n",
       "      <td>trocasse insinuacao bolsonaro ministros suprem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>@brussel_ive Infelizmente a grande massa de ap...</td>\n",
       "      <td>infelizmente grande massa apoiadores bolsonaro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>BOLSONARO REELEITO 22 ๐ง๐ท https://t.co/oCDy6E0h0e</td>\n",
       "      <td>bolsonaro reeleito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>Veja o que o PRESIDENTE BOLSONARO ACABOU de RE...</td>\n",
       "      <td>veja presidente bolsonaro acabou realizar bras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>A chefona da OMC..o mundo precisa do Brasil..o...</td>\n",
       "      <td>chefona omc  o mundo precisa brasil  o brasil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>@Aisha_com_vida nรบmeros que eu estudei pra sab...</td>\n",
       "      <td>numeros estudei pra saber ne  ja voce fica def...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>@GlauciaNatali @ericlinsg Glaucia, eu tenho ce...</td>\n",
       "      <td>glaucia  certeza militares  lado bolsonaro  ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>@lovefefoneto Assim, รฉ atรฉ que \"legal\" aq, mas...</td>\n",
       "      <td>assim   legal  aq  triste msm morar msm pais b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>@IsmaelxLucas Excelente! Tรก bom demais. \\nUm p...</td>\n",
       "      <td>excelente  ta bom demais  povinho elegeu bolso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Search  Tweet_Date                                     Original_Tweet  \\\n",
       "0  Bolsonaro  2022-04-23  @ArthurWilliam_ @LulaOficial @ricardostuckert ...   \n",
       "1  Bolsonaro  2022-04-23  @CarlosBolsonaro @TerraBrasilnot Se ele trocas...   \n",
       "2  Bolsonaro  2022-04-23  @brussel_ive Infelizmente a grande massa de ap...   \n",
       "3  Bolsonaro  2022-04-23   BOLSONARO REELEITO 22 ๐ง๐ท https://t.co/oCDy6E0h0e   \n",
       "4  Bolsonaro  2022-04-23  Veja o que o PRESIDENTE BOLSONARO ACABOU de RE...   \n",
       "5  Bolsonaro  2022-04-23  A chefona da OMC..o mundo precisa do Brasil..o...   \n",
       "6  Bolsonaro  2022-04-23  @Aisha_com_vida nรบmeros que eu estudei pra sab...   \n",
       "7  Bolsonaro  2022-04-23  @GlauciaNatali @ericlinsg Glaucia, eu tenho ce...   \n",
       "8  Bolsonaro  2022-04-23  @lovefefoneto Assim, รฉ atรฉ que \"legal\" aq, mas...   \n",
       "9  Bolsonaro  2022-04-23  @IsmaelxLucas Excelente! Tรก bom demais. \\nUm p...   \n",
       "\n",
       "                                        Cleaned_Text  \n",
       "0  antes  o ter sido presidente ter saqueado naca...  \n",
       "1  trocasse insinuacao bolsonaro ministros suprem...  \n",
       "2  infelizmente grande massa apoiadores bolsonaro...  \n",
       "3                                 bolsonaro reeleito  \n",
       "4  veja presidente bolsonaro acabou realizar bras...  \n",
       "5  chefona omc  o mundo precisa brasil  o brasil ...  \n",
       "6  numeros estudei pra saber ne  ja voce fica def...  \n",
       "7  glaucia  certeza militares  lado bolsonaro  ga...  \n",
       "8  assim   legal  aq  triste msm morar msm pais b...  \n",
       "9  excelente  ta bom demais  povinho elegeu bolso...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data['Cleaned_Text'] = preprocessing(data['Original_Tweet'])\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "mechanical-charlotte",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adopted-break",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 739 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['leia'] = data['Cleaned_Text'].apply(leia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "transparent-spokesman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['oplexion'] = data['Cleaned_Text'].apply(oplexion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sized-nicaragua",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['sentilex'] = data['Cleaned_Text'].apply(sentilex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "strong-intelligence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error to translate \"@taoquei1 @Rodrigo15121143 Boa noite Rodrigo e Barbara (Te Atualizei), eu achei Mรกxima essa jogada do Bolsonaro e tenho certeza que irรก entrar para a histรณria... ๐๐๐๐๐๐๐\"\n",
      "error to translate \"@o_antagonista DORIA PRESIDENTEEEEEEE\"\n",
      "Wall time: 20min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#se usar o texto limpo a acurรกcia fica muito baixa\n",
    "#isso acontece por causa da api nรฃo conseguir direito para inglรชs\n",
    "data['textblob'] = data['Original_Tweet'].apply(textblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ea53946-6455-4e3c-af68-edf4dde8bffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search</th>\n",
       "      <th>Tweet_Date</th>\n",
       "      <th>Original_Tweet</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>leia</th>\n",
       "      <th>oplexion</th>\n",
       "      <th>sentilex</th>\n",
       "      <th>textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>@taoquei1 @Rodrigo15121143 Boa noite Rodrigo e...</td>\n",
       "      <td>boa noite rodrigo barbara  te atualizei   ache...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>neutro</td>\n",
       "      <td>neutro</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>Doria</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>@o_antagonista DORIA PRESIDENTEEEEEEE</td>\n",
       "      <td>doria presidenteeeeeee</td>\n",
       "      <td>neutro</td>\n",
       "      <td>neutro</td>\n",
       "      <td>neutro</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Search  Tweet_Date  \\\n",
       "76    Bolsonaro  2022-04-23   \n",
       "2440      Doria  2022-04-23   \n",
       "\n",
       "                                         Original_Tweet  \\\n",
       "76    @taoquei1 @Rodrigo15121143 Boa noite Rodrigo e...   \n",
       "2440              @o_antagonista DORIA PRESIDENTEEEEEEE   \n",
       "\n",
       "                                           Cleaned_Text      leia oplexion  \\\n",
       "76    boa noite rodrigo barbara  te atualizei   ache...  positivo   neutro   \n",
       "2440                             doria presidenteeeeeee    neutro   neutro   \n",
       "\n",
       "     sentilex textblob  \n",
       "76     neutro     None  \n",
       "2440   neutro     None  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.textblob.isnull() == True].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81016575-a664-4acd-a5dc-0bb69d5c6ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Search          4000 non-null   object\n",
      " 1   Tweet_Date      4000 non-null   object\n",
      " 2   Original_Tweet  4000 non-null   object\n",
      " 3   Cleaned_Text    3866 non-null   object\n",
      " 4   leia            4000 non-null   object\n",
      " 5   oplexion        4000 non-null   object\n",
      " 6   sentilex        4000 non-null   object\n",
      " 7   textblob        3998 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 250.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b532bb3-2382-49c4-b008-0cf1e4a2eba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aggregate-technique",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Original_Tweet</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>leia</th>\n",
       "      <th>oplexion</th>\n",
       "      <th>sentilex</th>\n",
       "      <th>textblob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tweet_Date</th>\n",
       "      <th>Search</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2022-04-23</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <td>215</td>\n",
       "      <td>161</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ciro Gomes</th>\n",
       "      <td>163</td>\n",
       "      <td>150</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doria</th>\n",
       "      <td>246</td>\n",
       "      <td>207</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lula</th>\n",
       "      <td>205</td>\n",
       "      <td>180</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Original_Tweet  Cleaned_Text  leia  oplexion  sentilex  \\\n",
       "Tweet_Date Search                                                               \n",
       "2022-04-23 Bolsonaro              215           161   215       215       215   \n",
       "           Ciro Gomes             163           150   163       163       163   \n",
       "           Doria                  246           207   246       246       246   \n",
       "           Lula                   205           180   205       205       205   \n",
       "\n",
       "                       textblob  \n",
       "Tweet_Date Search                \n",
       "2022-04-23 Bolsonaro        215  \n",
       "           Ciro Gomes       163  \n",
       "           Doria            246  \n",
       "           Lula             205  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data.leia == data.oplexion) & (data.leia == data.sentilex) & (data.leia == data.textblob) & (data.leia == 'neutro')].groupby(['Tweet_Date', 'Search']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6127f8c0-00d4-41cd-8b7f-eadfcf79e714",
   "metadata": {},
   "outputs": [],
   "source": [
    "for search in data['Search'].value_counts().index.values:\n",
    "    for date in data['Tweet_Date'].value_counts().index.values:\n",
    "        data[(data.Search == search) & (data.Tweet_Date == date)].to_csv('clean_labeled_data\\\\'+search+'_'+date+'_clean_labeled.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
